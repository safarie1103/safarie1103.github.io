{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> Real Time Stock Ticker Streaming - Kafka Producer </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Data Overview:\n",
    "Stock data comes from yFinance. Using the API, we can get historical data as well as live data(when market is open), fo one or more stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import pandas\n",
    "\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import csv\n",
    "from datetime import timezone\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import datetime\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \n",
    "\n",
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical data for the given list of stocks\n",
    "def GetHistoricalData(stock_list,numberOfYears = 0,numberOfMonths = 4):\n",
    "    #print(numberOfMonths)\n",
    "    end = datetime.now()\n",
    "    start = datetime(end.year -  numberOfYears, end.month - numberOfMonths, end.day , end.hour, end.minute,end.second)\n",
    "    \n",
    "    historicalData = []\n",
    "    for stock in stock_list:\n",
    "        #print(start,end)\n",
    "        df = yf.download(stock, start, end)\n",
    "        df = df.reset_index()\n",
    "        df['Label'] = stock\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        historicalData.append(df)\n",
    "    return(historicalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Live data for the given stock\n",
    "def GetLiveData(symbol):\n",
    "    ticker = yf.Ticker(symbol).info\n",
    "    market_price = ticker['regularMarketPrice']\n",
    "    market_open = ticker['regularMarketOpen']\n",
    "    market_High = ticker['regularMarketDayHigh']\n",
    "    market_Low = ticker['regularMarketDayLow']\n",
    "    market_volume = ticker['regularMarketVolume']\n",
    "    market_symbol = ticker['symbol']\n",
    "    #print('Ticker: AMAT')\n",
    "    #print('Market Price:', market_price)\n",
    "    #print('Previous Close Price:', previous_close_price)\n",
    "    liveData = {'Date':[pd.to_datetime(datetime.now())],'Open': [market_open] , 'High':[market_High],'Low':[market_Low],'Close':[market_price],'Adj Close':[market_price],'Volume':[market_volume],'Label':[market_symbol]}\n",
    "    return(pd.DataFrame(liveData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "        Date        Open        High         Low       Close   Adj Close  \\\n",
      "0 2022-05-09  107.940002  110.790001  105.379997  105.750000  104.722122   \n",
      "1 2022-05-10  109.220001  109.570000  105.180000  107.180000  106.138222   \n",
      "2 2022-05-11  106.660004  109.129997  103.610001  103.919998  102.909912   \n",
      "3 2022-05-12  103.029999  106.879997  102.989998  106.760002  105.722305   \n",
      "4 2022-05-13  108.190002  112.629997  108.029999  111.860001  110.772728   \n",
      "\n",
      "     Volume Label  \n",
      "0  10088400  AMAT  \n",
      "1   8881000  AMAT  \n",
      "2   8311700  AMAT  \n",
      "3   9287100  AMAT  \n",
      "4   8321100  AMAT  \n"
     ]
    }
   ],
   "source": [
    "#Test historical Data of one year\n",
    "stock_list = ['AMAT','IBM','INTC']\n",
    "historicalData = GetHistoricalData(stock_list,1,0)\n",
    "print(historicalData[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test GetLiveData\n",
    "liveData = GetLiveData('AMAT')\n",
    "print(liveData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "#### Create publisher and producer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that publishes the message \n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    #print(data)\n",
    "    try:\n",
    "        producer_instance.send(topic_name, data)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "\n",
    "        \n",
    "# function that connects the kafka producer        \n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['192.168.86.48:9092'],\n",
    "                                  value_serializer=lambda x: dumps(x).encode('ascii'),\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "#### Send desired data batches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "   \n",
    "    \n",
    "        ## SET TOPIC AND DATA TO BE SENT\n",
    "\n",
    "        topic = 'stock_ticker'\n",
    "\n",
    "        #all_data = df.to_dict(orient='records')\n",
    "\n",
    "        ## SET THE PRODUCERS\n",
    "\n",
    "        producer = connect_kafka_producer()\n",
    "\n",
    "        getLiveData = False\n",
    "\n",
    "        ## GET DATA AND META DATA FOR EACH KEY\n",
    "\n",
    "\n",
    "        iteration_counter = 0\n",
    "\n",
    "        #stock_list = ['AMAT','LRCX','WOLF','KLAC','AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
    "        stock_list = ['AMAT','GOOG', 'MSFT','AMZN']\n",
    "        #stock_list = ['AMAT']\n",
    "        #stock_list = ['AMAT','LRCX','WOLF','KLAC']\n",
    "        # start the data publishing process\n",
    "        #print('Publishing records for ', stock_list, '..')\n",
    "\n",
    "        # set a continous loop to produce and publish data\n",
    "        \n",
    "        #print(len(df_Historical))\n",
    "        month = 3\n",
    "        df_Historical = GetHistoricalData(stock_list,2,0)\n",
    "        while True:\n",
    "            \"\"\"\n",
    "            if month == 0:\n",
    "                month = 3\n",
    "            df_Historical = GetHistoricalData(stock_list,1,month)\n",
    "            \n",
    "            month = month - 1\n",
    "            \"\"\"\n",
    "            for stock in range(len(df_Historical)):\n",
    "                if getLiveData:\n",
    "                    symbol = df_Historical[stock]['Label'][0]\n",
    "                    liveData = GetLiveData(symbol)\n",
    "                    liveData['Date'] = pd.to_datetime(liveData['Date'])\n",
    "                    df_Historical[stock] = pandas.concat([df_Historical[stock],liveData], ignore_index=True)\n",
    "                df_Historical[stock]['Date'] = df_Historical[stock]['Date'].astype(str)\n",
    "                sleep(20)\n",
    "\n",
    "            all_data = []\n",
    "            for stock in range(len(df_Historical)):\n",
    "                all_data.append(df_Historical[stock].to_dict(orient='records'))\n",
    "\n",
    "\n",
    "            publish_message(producer, topic, all_data)\n",
    "\n",
    "\n",
    "\n",
    "            if iteration_counter > 1000:\n",
    "                    break\n",
    "\n",
    "            iteration_counter += 1   \n",
    "\n",
    "            # send producer to sleep \n",
    "            sleep(30)\n",
    "        print(\"Exited with \", iteration_counter, \" iterations\")\n",
    "    except Exception as ex:\n",
    "        print(\"exception after \", iteration_counter, \" iterations\")\n",
    "        print(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
